{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":104,"outputs":[{"output_type":"stream","text":"/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\n/kaggle/input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip\n/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip\n/kaggle/input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nimport keras\nfrom keras import layers","execution_count":105,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# constants\nBASE_PATH = '../input/jigsaw-toxic-comment-classification-challenge/'\nTRAIN_PATH = 'train.csv.zip'\nTEST_PATH = 'test.csv.zip'\nLABELS = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\nNUM_CLASSES = 6","execution_count":106,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load train test dataframe\ntrain = pd.read_csv(f\"{BASE_PATH}{TRAIN_PATH}\")\ntest = pd.read_csv(f\"{BASE_PATH}{TEST_PATH}\")","execution_count":107,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_text = train['comment_text'].to_list()\ntrain_labels = train[LABELS].values\ntest_text = test['comment_text'].to_list()","execution_count":108,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_text(text):\n    text = text.lower()\n    text = re.sub(\"'\", \"\", text)\n    words = re.split(r'\\W+', text)\n    text = \" \".join(words)\n    text = re.sub(\"\\d+\", \"\", text)\n    text = \" \".join(text.split())\n    return text.strip()","execution_count":109,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clean_train_text = list(map(clean_text, train_text))\nclean_test_text = list(map(clean_text, test_text))","execution_count":110,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get count vectorizer and tf-idf transformer\ndef get_vectorizers(texts, max_features):\n    \"\"\"\n    :param texts: list of strings\n    :param max_features: max number of words in vocab\n    :return: tuple of count vectorizer and tf-idf transformer\n    \"\"\"\n    count_vectorizer = CountVectorizer(max_features=max_features, max_df=0.5).fit(texts)\n    counts = count_vectorizer.transform(texts)\n    tfidf_transformer = TfidfTransformer().fit(counts)\n    return count_vectorizer, tfidf_transformer","execution_count":111,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus = clean_train_text.copy()\ncorpus.extend(clean_test_text)\ncount_vectorizer, tfidf_transformer = get_vectorizers(corpus, 100)","execution_count":112,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = tfidf_transformer.transform(count_vectorizer.transform(clean_train_text)).toarray()\ntest_data = tfidf_transformer.transform(count_vectorizer.transform(clean_test_text)).toarray()","execution_count":113,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.shape","execution_count":114,"outputs":[{"output_type":"execute_result","execution_count":114,"data":{"text/plain":"(159571, 100)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.shape","execution_count":115,"outputs":[{"output_type":"execute_result","execution_count":115,"data":{"text/plain":"(153164, 100)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# training\ninputs = keras.Input(shape=(100,))\ndense_1 = layers.Dense(32, activation='relu')(inputs)\ndense_1 = layers.BatchNormalization()(dense_1)\ndense_1 = layers.Dropout(0.2)(dense_1)\n\noutputs = layers.Dense(NUM_CLASSES, activation='sigmoid')(dense_1)\n\nmodel = keras.Model(inputs=inputs, outputs=outputs)","execution_count":116,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":117,"outputs":[{"output_type":"stream","text":"Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_2 (InputLayer)         [(None, 100)]             0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 32)                3232      \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 32)                128       \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 32)                0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 6)                 198       \n=================================================================\nTotal params: 3,558\nTrainable params: 3,494\nNon-trainable params: 64\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n    loss='binary_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy']\n)","execution_count":118,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train_data, train_labels, epochs=20, batch_size=64, validation_split=0.2)","execution_count":124,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n1995/1995 [==============================] - 4s 2ms/step - loss: 0.0959 - accuracy: 0.9921 - val_loss: 0.0957 - val_accuracy: 0.9926\nEpoch 2/10\n1995/1995 [==============================] - 4s 2ms/step - loss: 0.0960 - accuracy: 0.9915 - val_loss: 0.0956 - val_accuracy: 0.9941\nEpoch 3/10\n1995/1995 [==============================] - 4s 2ms/step - loss: 0.0956 - accuracy: 0.9934 - val_loss: 0.0959 - val_accuracy: 0.9932\nEpoch 4/10\n1995/1995 [==============================] - 4s 2ms/step - loss: 0.0955 - accuracy: 0.9933 - val_loss: 0.0955 - val_accuracy: 0.9939\nEpoch 5/10\n1995/1995 [==============================] - 4s 2ms/step - loss: 0.0954 - accuracy: 0.9923 - val_loss: 0.0958 - val_accuracy: 0.9941\nEpoch 6/10\n1995/1995 [==============================] - 4s 2ms/step - loss: 0.0953 - accuracy: 0.9927 - val_loss: 0.0960 - val_accuracy: 0.9933\nEpoch 7/10\n1995/1995 [==============================] - 4s 2ms/step - loss: 0.0952 - accuracy: 0.9922 - val_loss: 0.0956 - val_accuracy: 0.9927\nEpoch 8/10\n1995/1995 [==============================] - 4s 2ms/step - loss: 0.0950 - accuracy: 0.9919 - val_loss: 0.0957 - val_accuracy: 0.9904\nEpoch 9/10\n1995/1995 [==============================] - 4s 2ms/step - loss: 0.0949 - accuracy: 0.9920 - val_loss: 0.0957 - val_accuracy: 0.9876\nEpoch 10/10\n1995/1995 [==============================] - 4s 2ms/step - loss: 0.0947 - accuracy: 0.9906 - val_loss: 0.0960 - val_accuracy: 0.9902\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_labels = model.predict(test_data)","execution_count":120,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ids = test[\"id\"].to_list()\nres = []\nfor idx, label in zip(ids, test_labels):\n    res.append([idx, *label])","execution_count":121,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out_df = pd.DataFrame(res, columns=[\"id\", *LABELS])","execution_count":122,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out_df.to_csv(\"out.csv\", index=False)","execution_count":123,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}